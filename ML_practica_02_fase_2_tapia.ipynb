{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ups logo](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Logo_Universidad_Polit%C3%A9cnica_Salesiana_del_Ecuador.png/640px-Logo_Universidad_Polit%C3%A9cnica_Salesiana_del_Ecuador.png)\n",
    "\n",
    "# Aprendizaje Automático P64\n",
    "\n",
    "# Practica 02\n",
    "\n",
    "\n",
    "## Redes Neuronales Problemas Multiclase y Optimización (fine tunning)\n",
    "\n",
    "## Fase 2: Optimización de una red neuronal para clasificación multiclase con imágenes \n",
    "\n",
    "## Autor: Diego Tapia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 18:43:57.509098: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 18:43:57.513384: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 18:43:57.572959: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 18:43:59.173829: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Módulos y clases importados\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from time import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn import set_config   \n",
    "\n",
    "print(\"Módulos y clases importados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del dataset\n",
    "\n",
    "Se carga el dataset CIFAR10 de la libreria de keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "cifar10.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación de los datos\n",
    "\n",
    "Se transforman las imágenes para ser usadas en una red neuronal clásica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalización lista!\n",
      "x: 89\n",
      "x': 0.34901960784313724\n"
     ]
    }
   ],
   "source": [
    "# Normalizamos tanto X_train como X_test, en este caso de forma sencilla porque los valores de los pixeles van de 0 a 255.\n",
    "x_train = X_train/255\n",
    "x_test = X_test/255\n",
    "print(\"Normalización lista!\")\n",
    "\n",
    "#Ejemplo para verificar\n",
    "print('x:',X_test[9999,1,1,1])\n",
    "print(\"\"\"x':\"\"\",x_test[9999,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "#Para transformar X en estructura clásica de ML (2D) para aplicar técnicas como SVM, Redes Neuronales Densas, KNN, etc.\n",
    "X_trainReshapeImageRow=x_train.reshape((x_train.shape[0],3072))\n",
    "print(X_trainReshapeImageRow.shape)\n",
    "X_testReshapeImageRow=x_test.reshape((x_test.shape[0],3072))\n",
    "print(X_testReshapeImageRow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se unen los conjuntos de train y test para usar en la función GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar conjunto entrenamiento y prueba en una sola variable \"Y\"\n",
    "Y = np.concatenate((y_train, y_test), axis=0)\n",
    "# Se carga en Xt los conjuntos de entrenamiento y testing convertidos\n",
    "Xt = np.concatenate((X_trainReshapeImageRow, X_testReshapeImageRow), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Parámetros de compilación\n",
    "\n",
    "En este paso se ajustará los valores de: batch_size, epochs y optimizer. El objetivo es encontrar la mejor combinación entre estos parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para convertir el tiempo de segundos al formato de días, horas, minutos y segundos.\n",
    "def GetTime(gs_time):\n",
    "    sec=timedelta(seconds=gs_time)\n",
    "    d = datetime(1,1,1) + sec\n",
    "    tiempoTotal=(\"%d días: %d horas: %d min: %d seg\" % (d.day-1, d.hour, d.minute, d.second))\n",
    "    return tiempoTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del pipeline (opcional)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "\n",
    "  model = Sequential([\n",
    "      Dense(32, input_dim=X_trainReshapeImageRow.shape[1], activation='relu'),\n",
    "      Dense(10, activation='softmax')\n",
    "  ])\n",
    "  #compilamos el modelo\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea listas que contienen los valores de los parámetros que se busca optimizar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[['modelNN',\n",
      "                 KerasClassifier(model=<function create_model at 0x7a33961a6700>, verbose=0)]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = [32,64,128,256,512,1024]\n",
    "epochs = [10,25,50,75,100,150] \n",
    "optimizer = ['RMSprop','Adam']\n",
    "\n",
    "\n",
    "#parámetros que queremos probar, y sus valores \n",
    "parameters = {'modelNN__batch_size': batch_size,\n",
    "             'modelNN__epochs': epochs,\n",
    "             'modelNN__optimizer': optimizer}\n",
    "\n",
    "estimator = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "pipe.steps.append(['modelNN',estimator])\n",
    "\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se empieza a buscar la mejor combinación de parámetros con la función ```GridSearchCV```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se toma el tiempo inicial para calcular el tiempo de ejecución \n",
    "tic = time()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid=parameters, scoring='accuracy', cv=5, n_jobs=6, error_score='raise')\n",
    "\n",
    "grid_result = grid_search.fit(Xt, Y)\n",
    "\n",
    "print(grid_result.best_params_)\n",
    "\n",
    "\n",
    "gs_time = time() - tic\n",
    "print('Tiempo en segundos: ',gs_time)\n",
    "tiempoTotal=GetTime(gs_time)\n",
    "print('Tiempo: ',tiempoTotal)\n",
    "\n",
    "gs1=grid_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
