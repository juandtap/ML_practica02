{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ups logo](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Logo_Universidad_Polit%C3%A9cnica_Salesiana_del_Ecuador.png/640px-Logo_Universidad_Polit%C3%A9cnica_Salesiana_del_Ecuador.png)\n",
    "\n",
    "# Aprendizaje Automático P64\n",
    "\n",
    "# Practica 02\n",
    "\n",
    "\n",
    "## Redes Neuronales Problemas Multiclase y Optimización (fine tunning)\n",
    "\n",
    "## Fase 2: Optimización de una red neuronal para clasificación multiclase con imágenes \n",
    "\n",
    "## Autor: Diego Tapia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Módulos y clases importados\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from time import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn import set_config   \n",
    "\n",
    "print(\"Módulos y clases importados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del dataset\n",
    "\n",
    "Se carga el dataset CIFAR10 de la libreria de keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "cifar10.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación de los datos\n",
    "\n",
    "Se transforman las imágenes para ser usadas en una red neuronal clásica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalización lista!\n",
      "x: 89\n",
      "x': 0.34901960784313724\n"
     ]
    }
   ],
   "source": [
    "# Normalizamos tanto X_train como X_test, en este caso de forma sencilla porque los valores de los pixeles van de 0 a 255.\n",
    "x_train = X_train/255\n",
    "x_test = X_test/255\n",
    "print(\"Normalización lista!\")\n",
    "\n",
    "#Ejemplo para verificar\n",
    "print('x:',X_test[9999,1,1,1])\n",
    "print(\"\"\"x':\"\"\",x_test[9999,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "#Para transformar X en estructura clásica de ML (2D) para aplicar técnicas como SVM, Redes Neuronales Densas, KNN, etc.\n",
    "X_trainReshapeImageRow=x_train.reshape((x_train.shape[0],3072))\n",
    "print(X_trainReshapeImageRow.shape)\n",
    "X_testReshapeImageRow=x_test.reshape((x_test.shape[0],3072))\n",
    "print(X_testReshapeImageRow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Parámetros de compilación\n",
    "\n",
    "En este paso se ajustará los valores de: batch_size, epochs y optimizer. El objetivo es encontrar la mejor combinación entre estos parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para convertir el tiempo de segundos al formato de días, horas, minutos y segundos.\n",
    "def GetTime(gs_time):\n",
    "    sec=timedelta(seconds=gs_time)\n",
    "    d = datetime(1,1,1) + sec\n",
    "    tiempoTotal=(\"%d días: %d horas: %d min: %d seg\" % (d.day-1, d.hour, d.minute, d.second))\n",
    "    return tiempoTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del pipeline (opcional)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "\n",
    "  model = Sequential([\n",
    "      Dense(32, input_dim=X_trainReshapeImageRow.shape[1], activation='relu'),\n",
    "      Dense(10, activation='softmax')\n",
    "  ])\n",
    "  #compilamos el modelo\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea listas que contienen los valores de los parámetros que se busca optimizar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[['modelNN',\n",
      "                 KerasClassifier(model=<function create_model at 0x000002A2CF440790>, verbose=0)]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = [32,64,128,256]\n",
    "epochs = [10,25,50,77] \n",
    "optimizer = ['RMSprop','Adam']\n",
    "\n",
    "\n",
    "#parámetros que queremos probar, y sus valores \n",
    "parameters = {'modelNN__batch_size': batch_size,\n",
    "             'modelNN__epochs': epochs,\n",
    "             'modelNN__optimizer': optimizer}\n",
    "\n",
    "estimator = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "pipe.steps.append(['modelNN',estimator])\n",
    "\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se empieza a buscar la mejor combinación de parámetros con la función ```GridSearchCV```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frank\\Desktop\\diego\\ML_practica02\\venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modelNN__batch_size': 256, 'modelNN__epochs': 77, 'modelNN__optimizer': 'RMSprop'}\n",
      "Tiempo en segundos:  2928.8211238384247\n",
      "Tiempo:  0 días: 0 horas: 48 min: 48 seg\n"
     ]
    }
   ],
   "source": [
    "# se toma el tiempo inicial para calcular el tiempo de ejecución \n",
    "tic = time()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid=parameters, scoring='accuracy', cv=5, n_jobs=9, error_score='raise')\n",
    "\n",
    "grid_result = grid_search.fit(X_trainReshapeImageRow, y_train)\n",
    "\n",
    "print(grid_result.best_params_)\n",
    "\n",
    "\n",
    "gs_time = time() - tic\n",
    "print('Tiempo en segundos: ',gs_time)\n",
    "tiempoTotal=GetTime(gs_time)\n",
    "print('Tiempo: ',tiempoTotal)\n",
    "\n",
    "gs1=grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.369140 using {'modelNN__batch_size': 256, 'modelNN__epochs': 77, 'modelNN__optimizer': 'RMSprop'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (gs1.best_score_, gs1.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.244040 (0.074066) with: {'modelNN__batch_size': 32, 'modelNN__epochs': 10, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.267360 (0.024362) with: {'modelNN__batch_size': 32, 'modelNN__epochs': 10, 'modelNN__optimizer': 'Adam'}\n",
      "0.211420 (0.076261) with: {'modelNN__batch_size': 32, 'modelNN__epochs': 25, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.230220 (0.057712) with: {'modelNN__batch_size': 32, 'modelNN__epochs': 25, 'modelNN__optimizer': 'Adam'}\n",
      "0.286040 (0.065716) with: {'modelNN__batch_size': 32, 'modelNN__epochs': 50, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.240180 (0.074462) with: {'modelNN__batch_size': 32, 'modelNN__epochs': 50, 'modelNN__optimizer': 'Adam'}\n",
      "0.201000 (0.059475) with: {'modelNN__batch_size': 32, 'modelNN__epochs': 77, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.231220 (0.054757) with: {'modelNN__batch_size': 32, 'modelNN__epochs': 77, 'modelNN__optimizer': 'Adam'}\n",
      "0.204120 (0.069341) with: {'modelNN__batch_size': 64, 'modelNN__epochs': 10, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.290140 (0.049333) with: {'modelNN__batch_size': 64, 'modelNN__epochs': 10, 'modelNN__optimizer': 'Adam'}\n",
      "0.287480 (0.034214) with: {'modelNN__batch_size': 64, 'modelNN__epochs': 25, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.307960 (0.034067) with: {'modelNN__batch_size': 64, 'modelNN__epochs': 25, 'modelNN__optimizer': 'Adam'}\n",
      "0.293160 (0.059796) with: {'modelNN__batch_size': 64, 'modelNN__epochs': 50, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.230440 (0.112126) with: {'modelNN__batch_size': 64, 'modelNN__epochs': 50, 'modelNN__optimizer': 'Adam'}\n",
      "0.215780 (0.056886) with: {'modelNN__batch_size': 64, 'modelNN__epochs': 77, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.244580 (0.101449) with: {'modelNN__batch_size': 64, 'modelNN__epochs': 77, 'modelNN__optimizer': 'Adam'}\n",
      "0.276400 (0.055123) with: {'modelNN__batch_size': 128, 'modelNN__epochs': 10, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.271860 (0.077720) with: {'modelNN__batch_size': 128, 'modelNN__epochs': 10, 'modelNN__optimizer': 'Adam'}\n",
      "0.325960 (0.038980) with: {'modelNN__batch_size': 128, 'modelNN__epochs': 25, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.274600 (0.066463) with: {'modelNN__batch_size': 128, 'modelNN__epochs': 25, 'modelNN__optimizer': 'Adam'}\n",
      "0.310480 (0.066700) with: {'modelNN__batch_size': 128, 'modelNN__epochs': 50, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.274620 (0.098453) with: {'modelNN__batch_size': 128, 'modelNN__epochs': 50, 'modelNN__optimizer': 'Adam'}\n",
      "0.291380 (0.051837) with: {'modelNN__batch_size': 128, 'modelNN__epochs': 77, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.311400 (0.097392) with: {'modelNN__batch_size': 128, 'modelNN__epochs': 77, 'modelNN__optimizer': 'Adam'}\n",
      "0.299480 (0.100173) with: {'modelNN__batch_size': 256, 'modelNN__epochs': 10, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.296700 (0.031068) with: {'modelNN__batch_size': 256, 'modelNN__epochs': 10, 'modelNN__optimizer': 'Adam'}\n",
      "0.314640 (0.068094) with: {'modelNN__batch_size': 256, 'modelNN__epochs': 25, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.311440 (0.049089) with: {'modelNN__batch_size': 256, 'modelNN__epochs': 25, 'modelNN__optimizer': 'Adam'}\n",
      "0.302100 (0.076930) with: {'modelNN__batch_size': 256, 'modelNN__epochs': 50, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.367380 (0.034369) with: {'modelNN__batch_size': 256, 'modelNN__epochs': 50, 'modelNN__optimizer': 'Adam'}\n",
      "0.369140 (0.035666) with: {'modelNN__batch_size': 256, 'modelNN__epochs': 77, 'modelNN__optimizer': 'RMSprop'}\n",
      "0.328940 (0.035184) with: {'modelNN__batch_size': 256, 'modelNN__epochs': 77, 'modelNN__optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "means = gs1.cv_results_['mean_test_score']\n",
    "stds = gs1.cv_results_['std_test_score']\n",
    "params = gs1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Densidad de las capas de neuronas y regularización de Dropout\n",
    "En este paso se ajusta la cantidad (densidad) de neuronas en las capas de la red. También, en este paso se ajusta los valores de dropout en las capas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el modelo de red neuronal, para la optimizacion de las capas se usa el estimador \"RMSProp\"  que fue mejor que adam en la busqueda del mejores parametros de compilación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps=[]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def create_model_op(l1,l2,dr):\n",
    "    model = Sequential([\n",
    "        Dense(l1, input_dim=X_trainReshapeImageRow.shape[1], activation='relu'),\n",
    "        Dropout(dr),\n",
    "        Dense(l2, activation='relu'),\n",
    "        Dropout(dr),\n",
    "        # Capa de salida\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        optimizer='RMSprop', \n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen los valores de las capas y el dropout, para el Clasificador usamos los parametros de compilación óptimos encontrados en el paso anterior (epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[['modelNN',\n",
      "                 KerasClassifier(batch_size=256, dr=0.2, epochs=75, l1=16, l2=16, model=<function create_model_op at 0x000002A38264F400>, verbose=0)]])\n"
     ]
    }
   ],
   "source": [
    "l1=[16, 32, 48]\n",
    "l2=[16, 32, 48]\n",
    "dr=[0, 0.2, 0.35]\n",
    "\n",
    "parameters = {'modelNN__l1':l1,\n",
    "            'modelNN__l2':l2,\n",
    "            'modelNN__dr':dr}\n",
    "\n",
    "\n",
    "estimator = KerasClassifier(model=create_model_op, verbose=0, batch_size=256, epochs=75, l1=16, l2=16, dr=0.2)\n",
    "\n",
    "pipe.steps.append(['modelNN',estimator])\n",
    "\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frank\\Desktop\\diego\\ML_practica02\\venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en segundos:  2178.6005222797394\n",
      "Tiempo:  0 días: 0 horas: 36 min: 18 seg\n",
      "Best: 0.432040 using {'modelNN__dr': 0, 'modelNN__l1': 48, 'modelNN__l2': 48}\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid=parameters, scoring='accuracy', cv=5, n_jobs=10)\n",
    "grid_result = grid_search.fit(X_trainReshapeImageRow, y_train)\n",
    "\n",
    "\n",
    "gs_time1 = time() - tic\n",
    "print('Tiempo en segundos: ',gs_time1)\n",
    "tiempoTotal=GetTime(gs_time1)\n",
    "print('Tiempo: ',tiempoTotal)\n",
    "\n",
    "gs2=grid_result\n",
    "\n",
    "print(\"Best: %f using %s\" % (gs2.best_score_, gs2.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
